{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2188d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyvista as pv\n",
    "import shapeworks as sw\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pathlib import Path\n",
    "from scipy.spatial import cKDTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3252cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "muscle_name = 'semimembranosus'  # Change this to the desired muscle name\n",
    "side = 'left'\n",
    "modifiers = ['rigid', 'novolume']\n",
    "\n",
    "# Define directories\n",
    "data_dir = \"data/\"\n",
    "muscle_dir = f\"{data_dir}{muscle_name}/\"\n",
    "bin_dir = f\"{muscle_dir}bin/\"\n",
    "base_dir = \"projects/\"\n",
    "project_dir = f\"{base_dir}{muscle_name}/\"\n",
    "\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "os.makedirs(project_dir, exist_ok=True)\n",
    "\n",
    "for modifier in modifiers:\n",
    "    mesh_dir = f\"{muscle_dir}mesh_{modifier}/{side}/\"\n",
    "    spreadsheet_file = f\"{project_dir}{muscle_name}_{modifier}_{side}.swproj\"\n",
    "    output_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_analysis\")\n",
    "    output_dir.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7f79756",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load metadata from Excel\n",
    "meta = pd.read_excel(\"MOTION_characteristics.xlsx\")\n",
    "\n",
    "# Normalize columns to lower-case\n",
    "meta.columns = [c.lower() for c in meta.columns]\n",
    "\n",
    "# Determine correct ID column name\n",
    "id_col = [c for c in meta.columns if \"participant\" in c and \"id\" in c][0]  # auto-detect\n",
    "sex_col = [c for c in meta.columns if \"sex\" in c][0]\n",
    "\n",
    "# Build ID â†’ sex mapping\n",
    "# MRI_Sex: 1 = male, 2 = female\n",
    "id_to_sex = {}\n",
    "for _, row in meta.iterrows():\n",
    "    pid = str(row[id_col]).strip()\n",
    "    sex_num = row[sex_col]\n",
    "    if sex_num == 1:\n",
    "        id_to_sex[pid] = \"male\"\n",
    "    elif sex_num == 2:\n",
    "        id_to_sex[pid] = \"female\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccddb6f9",
   "metadata": {},
   "source": [
    "# Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9710fd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Processing modifier: rigid ===\n",
      " Total number of distance transform files: 101\n",
      " Shape names: ['MOTION001_left', 'MOTION002_left', 'MOTION003_left', 'MOTION004_left', 'MOTION005_left', 'MOTION006_left', 'MOTION007_left', 'MOTION008_left', 'MOTION009_left', 'MOTION010_left', 'MOTION011_left', 'MOTION012_left', 'MOTION013_left', 'MOTION014_left', 'MOTION015_left', 'MOTION016_left', 'MOTION017_left', 'MOTION018_left', 'MOTION019_left', 'MOTION020_left', 'MOTION021_left', 'MOTION022_left', 'MOTION023_left', 'MOTION024_left', 'MOTION025_left', 'MOTION026_left', 'MOTION027_left', 'MOTION028_left', 'MOTION029_left', 'MOTION030_left', 'MOTION031_left', 'MOTION032_left', 'MOTION033_left', 'MOTION034_left', 'MOTION035_left', 'MOTION036_left', 'MOTION037_left', 'MOTION038_left', 'MOTION039_left', 'MOTION040_left', 'MOTION041_left', 'MOTION042_left', 'MOTION043_left', 'MOTION044_left', 'MOTION045_left', 'MOTION046_left', 'MOTION047_left', 'MOTION048_left', 'MOTION049_left', 'MOTION050_left', 'MOTION051_left', 'MOTION052_left', 'MOTION053_left', 'MOTION054_left', 'MOTION055_left', 'MOTION056_left', 'MOTION057_left', 'MOTION058_left', 'MOTION059_left', 'MOTION060_left', 'MOTION061_left', 'MOTION062_left', 'MOTION063_left', 'MOTION064_left', 'MOTION065_left', 'MOTION066_left', 'MOTION067_left', 'MOTION068_left', 'MOTION069_left', 'MOTION070_left', 'MOTION071_left', 'MOTION072_left', 'MOTION073_left', 'MOTION074_left', 'MOTION075_left', 'MOTION076_left', 'MOTION077_left', 'MOTION078_left', 'MOTION079_left', 'MOTION080_left', 'MOTION081_left', 'MOTION082_left', 'MOTION083_left', 'MOTION084_left', 'MOTION085_left', 'MOTION086_left', 'MOTION087_left', 'MOTION088_left', 'MOTION089_left', 'MOTION090_left', 'MOTION091_left', 'MOTION092_left', 'MOTION093_left', 'MOTION094_left', 'MOTION095_left', 'MOTION096_left', 'MOTION097_left', 'MOTION098_left', 'MOTION099_left', 'MOTION100_left', 'MOTION101_left']\n",
      " âœ… Added subject 1: MOTION001_left  â†’  male\n",
      " âœ… Added subject 2: MOTION002_left  â†’  male\n",
      " âœ… Added subject 3: MOTION003_left  â†’  female\n",
      " âœ… Added subject 4: MOTION004_left  â†’  female\n",
      " âœ… Added subject 5: MOTION005_left  â†’  female\n",
      " âœ… Added subject 6: MOTION006_left  â†’  male\n",
      " âœ… Added subject 7: MOTION007_left  â†’  male\n",
      " âœ… Added subject 8: MOTION008_left  â†’  male\n",
      " âœ… Added subject 9: MOTION009_left  â†’  female\n",
      " âœ… Added subject 10: MOTION010_left  â†’  female\n",
      " âœ… Added subject 11: MOTION011_left  â†’  female\n",
      " âœ… Added subject 12: MOTION012_left  â†’  male\n",
      " âœ… Added subject 13: MOTION013_left  â†’  male\n",
      " âœ… Added subject 14: MOTION014_left  â†’  female\n",
      " âœ… Added subject 15: MOTION015_left  â†’  male\n",
      " âœ… Added subject 16: MOTION016_left  â†’  male\n",
      " âœ… Added subject 17: MOTION017_left  â†’  male\n",
      " âœ… Added subject 18: MOTION018_left  â†’  female\n",
      " âœ… Added subject 19: MOTION019_left  â†’  female\n",
      " âœ… Added subject 20: MOTION020_left  â†’  female\n",
      " âœ… Added subject 21: MOTION021_left  â†’  male\n",
      " âœ… Added subject 22: MOTION022_left  â†’  female\n",
      " âœ… Added subject 23: MOTION023_left  â†’  female\n",
      " âœ… Added subject 24: MOTION024_left  â†’  male\n",
      " âœ… Added subject 25: MOTION025_left  â†’  female\n",
      " âœ… Added subject 26: MOTION026_left  â†’  female\n",
      " âœ… Added subject 27: MOTION027_left  â†’  male\n",
      " âœ… Added subject 28: MOTION028_left  â†’  male\n",
      " âœ… Added subject 29: MOTION029_left  â†’  female\n",
      " âœ… Added subject 30: MOTION030_left  â†’  male\n",
      " âœ… Added subject 31: MOTION031_left  â†’  female\n",
      " âœ… Added subject 32: MOTION032_left  â†’  female\n",
      " âœ… Added subject 33: MOTION033_left  â†’  male\n",
      " âœ… Added subject 34: MOTION034_left  â†’  female\n",
      " âœ… Added subject 35: MOTION035_left  â†’  female\n",
      " âœ… Added subject 36: MOTION036_left  â†’  female\n",
      " âœ… Added subject 37: MOTION037_left  â†’  female\n",
      " âœ… Added subject 38: MOTION038_left  â†’  female\n",
      " âœ… Added subject 39: MOTION039_left  â†’  female\n",
      " âœ… Added subject 40: MOTION040_left  â†’  male\n",
      " âœ… Added subject 41: MOTION041_left  â†’  female\n",
      " âœ… Added subject 42: MOTION042_left  â†’  female\n",
      " âœ… Added subject 43: MOTION043_left  â†’  female\n",
      " âœ… Added subject 44: MOTION044_left  â†’  female\n",
      " âœ… Added subject 45: MOTION045_left  â†’  female\n",
      " âœ… Added subject 46: MOTION046_left  â†’  male\n",
      " âœ… Added subject 47: MOTION047_left  â†’  female\n",
      " âœ… Added subject 48: MOTION048_left  â†’  male\n",
      " âœ… Added subject 49: MOTION049_left  â†’  male\n",
      " âœ… Added subject 50: MOTION050_left  â†’  male\n",
      " âœ… Added subject 51: MOTION051_left  â†’  female\n",
      " âœ… Added subject 52: MOTION052_left  â†’  male\n",
      " âœ… Added subject 53: MOTION053_left  â†’  female\n",
      " âœ… Added subject 54: MOTION054_left  â†’  male\n",
      " âœ… Added subject 55: MOTION055_left  â†’  female\n",
      " âœ… Added subject 56: MOTION056_left  â†’  male\n",
      " âœ… Added subject 57: MOTION057_left  â†’  female\n",
      " âœ… Added subject 58: MOTION058_left  â†’  female\n",
      " âœ… Added subject 59: MOTION059_left  â†’  male\n",
      " âœ… Added subject 60: MOTION060_left  â†’  female\n",
      " âœ… Added subject 61: MOTION061_left  â†’  male\n",
      " âœ… Added subject 62: MOTION062_left  â†’  female\n",
      " âœ… Added subject 63: MOTION063_left  â†’  male\n",
      " âœ… Added subject 64: MOTION064_left  â†’  female\n",
      " âœ… Added subject 65: MOTION065_left  â†’  male\n",
      " âœ… Added subject 66: MOTION066_left  â†’  male\n",
      " âœ… Added subject 67: MOTION067_left  â†’  female\n",
      " âœ… Added subject 68: MOTION068_left  â†’  male\n",
      " âœ… Added subject 69: MOTION069_left  â†’  female\n",
      " âœ… Added subject 70: MOTION070_left  â†’  female\n",
      " âœ… Added subject 71: MOTION071_left  â†’  female\n",
      " âœ… Added subject 72: MOTION072_left  â†’  female\n",
      " âœ… Added subject 73: MOTION073_left  â†’  male\n",
      " âœ… Added subject 74: MOTION074_left  â†’  female\n",
      " âœ… Added subject 75: MOTION075_left  â†’  female\n",
      " âœ… Added subject 76: MOTION076_left  â†’  female\n",
      " âœ… Added subject 77: MOTION077_left  â†’  male\n",
      " âœ… Added subject 78: MOTION078_left  â†’  male\n",
      " âœ… Added subject 79: MOTION079_left  â†’  female\n",
      " âœ… Added subject 80: MOTION080_left  â†’  male\n",
      " âœ… Added subject 81: MOTION081_left  â†’  male\n",
      " âœ… Added subject 82: MOTION082_left  â†’  female\n",
      " âœ… Added subject 83: MOTION083_left  â†’  male\n",
      " âœ… Added subject 84: MOTION084_left  â†’  male\n",
      " âœ… Added subject 85: MOTION085_left  â†’  male\n",
      " âœ… Added subject 86: MOTION086_left  â†’  male\n",
      " âœ… Added subject 87: MOTION087_left  â†’  female\n",
      " âœ… Added subject 88: MOTION088_left  â†’  female\n",
      " âœ… Added subject 89: MOTION089_left  â†’  male\n",
      " âœ… Added subject 90: MOTION090_left  â†’  female\n",
      " âœ… Added subject 91: MOTION091_left  â†’  female\n",
      " âœ… Added subject 92: MOTION092_left  â†’  male\n",
      " âœ… Added subject 93: MOTION093_left  â†’  male\n",
      " âœ… Added subject 94: MOTION094_left  â†’  female\n",
      " âœ… Added subject 95: MOTION095_left  â†’  male\n",
      " âœ… Added subject 96: MOTION096_left  â†’  male\n",
      " âœ… Added subject 97: MOTION097_left  â†’  female\n",
      " âœ… Added subject 98: MOTION098_left  â†’  female\n",
      " âœ… Added subject 99: MOTION099_left  â†’  male\n",
      " âœ… Added subject 100: MOTION100_left  â†’  female\n",
      " âœ… Added subject 101: MOTION101_left  â†’  male\n",
      " ðŸ’¾ Project saved to projects/biceps_femoris_long/biceps_femoris_long_rigid_left.swproj\n",
      "\n",
      "=== Processing modifier: novolume ===\n",
      " Total number of distance transform files: 101\n",
      " Shape names: ['MOTION001_left', 'MOTION002_left', 'MOTION003_left', 'MOTION004_left', 'MOTION005_left', 'MOTION006_left', 'MOTION007_left', 'MOTION008_left', 'MOTION009_left', 'MOTION010_left', 'MOTION011_left', 'MOTION012_left', 'MOTION013_left', 'MOTION014_left', 'MOTION015_left', 'MOTION016_left', 'MOTION017_left', 'MOTION018_left', 'MOTION019_left', 'MOTION020_left', 'MOTION021_left', 'MOTION022_left', 'MOTION023_left', 'MOTION024_left', 'MOTION025_left', 'MOTION026_left', 'MOTION027_left', 'MOTION028_left', 'MOTION029_left', 'MOTION030_left', 'MOTION031_left', 'MOTION032_left', 'MOTION033_left', 'MOTION034_left', 'MOTION035_left', 'MOTION036_left', 'MOTION037_left', 'MOTION038_left', 'MOTION039_left', 'MOTION040_left', 'MOTION041_left', 'MOTION042_left', 'MOTION043_left', 'MOTION044_left', 'MOTION045_left', 'MOTION046_left', 'MOTION047_left', 'MOTION048_left', 'MOTION049_left', 'MOTION050_left', 'MOTION051_left', 'MOTION052_left', 'MOTION053_left', 'MOTION054_left', 'MOTION055_left', 'MOTION056_left', 'MOTION057_left', 'MOTION058_left', 'MOTION059_left', 'MOTION060_left', 'MOTION061_left', 'MOTION062_left', 'MOTION063_left', 'MOTION064_left', 'MOTION065_left', 'MOTION066_left', 'MOTION067_left', 'MOTION068_left', 'MOTION069_left', 'MOTION070_left', 'MOTION071_left', 'MOTION072_left', 'MOTION073_left', 'MOTION074_left', 'MOTION075_left', 'MOTION076_left', 'MOTION077_left', 'MOTION078_left', 'MOTION079_left', 'MOTION080_left', 'MOTION081_left', 'MOTION082_left', 'MOTION083_left', 'MOTION084_left', 'MOTION085_left', 'MOTION086_left', 'MOTION087_left', 'MOTION088_left', 'MOTION089_left', 'MOTION090_left', 'MOTION091_left', 'MOTION092_left', 'MOTION093_left', 'MOTION094_left', 'MOTION095_left', 'MOTION096_left', 'MOTION097_left', 'MOTION098_left', 'MOTION099_left', 'MOTION100_left', 'MOTION101_left']\n",
      " âœ… Added subject 1: MOTION001_left  â†’  male\n",
      " âœ… Added subject 2: MOTION002_left  â†’  male\n",
      " âœ… Added subject 3: MOTION003_left  â†’  female\n",
      " âœ… Added subject 4: MOTION004_left  â†’  female\n",
      " âœ… Added subject 5: MOTION005_left  â†’  female\n",
      " âœ… Added subject 6: MOTION006_left  â†’  male\n",
      " âœ… Added subject 7: MOTION007_left  â†’  male\n",
      " âœ… Added subject 8: MOTION008_left  â†’  male\n",
      " âœ… Added subject 9: MOTION009_left  â†’  female\n",
      " âœ… Added subject 10: MOTION010_left  â†’  female\n",
      " âœ… Added subject 11: MOTION011_left  â†’  female\n",
      " âœ… Added subject 12: MOTION012_left  â†’  male\n",
      " âœ… Added subject 13: MOTION013_left  â†’  male\n",
      " âœ… Added subject 14: MOTION014_left  â†’  female\n",
      " âœ… Added subject 15: MOTION015_left  â†’  male\n",
      " âœ… Added subject 16: MOTION016_left  â†’  male\n",
      " âœ… Added subject 17: MOTION017_left  â†’  male\n",
      " âœ… Added subject 18: MOTION018_left  â†’  female\n",
      " âœ… Added subject 19: MOTION019_left  â†’  female\n",
      " âœ… Added subject 20: MOTION020_left  â†’  female\n",
      " âœ… Added subject 21: MOTION021_left  â†’  male\n",
      " âœ… Added subject 22: MOTION022_left  â†’  female\n",
      " âœ… Added subject 23: MOTION023_left  â†’  female\n",
      " âœ… Added subject 24: MOTION024_left  â†’  male\n",
      " âœ… Added subject 25: MOTION025_left  â†’  female\n",
      " âœ… Added subject 26: MOTION026_left  â†’  female\n",
      " âœ… Added subject 27: MOTION027_left  â†’  male\n",
      " âœ… Added subject 28: MOTION028_left  â†’  male\n",
      " âœ… Added subject 29: MOTION029_left  â†’  female\n",
      " âœ… Added subject 30: MOTION030_left  â†’  male\n",
      " âœ… Added subject 31: MOTION031_left  â†’  female\n",
      " âœ… Added subject 32: MOTION032_left  â†’  female\n",
      " âœ… Added subject 33: MOTION033_left  â†’  male\n",
      " âœ… Added subject 34: MOTION034_left  â†’  female\n",
      " âœ… Added subject 35: MOTION035_left  â†’  female\n",
      " âœ… Added subject 36: MOTION036_left  â†’  female\n",
      " âœ… Added subject 37: MOTION037_left  â†’  female\n",
      " âœ… Added subject 38: MOTION038_left  â†’  female\n",
      " âœ… Added subject 39: MOTION039_left  â†’  female\n",
      " âœ… Added subject 40: MOTION040_left  â†’  male\n",
      " âœ… Added subject 41: MOTION041_left  â†’  female\n",
      " âœ… Added subject 42: MOTION042_left  â†’  female\n",
      " âœ… Added subject 43: MOTION043_left  â†’  female\n",
      " âœ… Added subject 44: MOTION044_left  â†’  female\n",
      " âœ… Added subject 45: MOTION045_left  â†’  female\n",
      " âœ… Added subject 46: MOTION046_left  â†’  male\n",
      " âœ… Added subject 47: MOTION047_left  â†’  female\n",
      " âœ… Added subject 48: MOTION048_left  â†’  male\n",
      " âœ… Added subject 49: MOTION049_left  â†’  male\n",
      " âœ… Added subject 50: MOTION050_left  â†’  male\n",
      " âœ… Added subject 51: MOTION051_left  â†’  female\n",
      " âœ… Added subject 52: MOTION052_left  â†’  male\n",
      " âœ… Added subject 53: MOTION053_left  â†’  female\n",
      " âœ… Added subject 54: MOTION054_left  â†’  male\n",
      " âœ… Added subject 55: MOTION055_left  â†’  female\n",
      " âœ… Added subject 56: MOTION056_left  â†’  male\n",
      " âœ… Added subject 57: MOTION057_left  â†’  female\n",
      " âœ… Added subject 58: MOTION058_left  â†’  female\n",
      " âœ… Added subject 59: MOTION059_left  â†’  male\n",
      " âœ… Added subject 60: MOTION060_left  â†’  female\n",
      " âœ… Added subject 61: MOTION061_left  â†’  male\n",
      " âœ… Added subject 62: MOTION062_left  â†’  female\n",
      " âœ… Added subject 63: MOTION063_left  â†’  male\n",
      " âœ… Added subject 64: MOTION064_left  â†’  female\n",
      " âœ… Added subject 65: MOTION065_left  â†’  male\n",
      " âœ… Added subject 66: MOTION066_left  â†’  male\n",
      " âœ… Added subject 67: MOTION067_left  â†’  female\n",
      " âœ… Added subject 68: MOTION068_left  â†’  male\n",
      " âœ… Added subject 69: MOTION069_left  â†’  female\n",
      " âœ… Added subject 70: MOTION070_left  â†’  female\n",
      " âœ… Added subject 71: MOTION071_left  â†’  female\n",
      " âœ… Added subject 72: MOTION072_left  â†’  female\n",
      " âœ… Added subject 73: MOTION073_left  â†’  male\n",
      " âœ… Added subject 74: MOTION074_left  â†’  female\n",
      " âœ… Added subject 75: MOTION075_left  â†’  female\n",
      " âœ… Added subject 76: MOTION076_left  â†’  female\n",
      " âœ… Added subject 77: MOTION077_left  â†’  male\n",
      " âœ… Added subject 78: MOTION078_left  â†’  male\n",
      " âœ… Added subject 79: MOTION079_left  â†’  female\n",
      " âœ… Added subject 80: MOTION080_left  â†’  male\n",
      " âœ… Added subject 81: MOTION081_left  â†’  male\n",
      " âœ… Added subject 82: MOTION082_left  â†’  female\n",
      " âœ… Added subject 83: MOTION083_left  â†’  male\n",
      " âœ… Added subject 84: MOTION084_left  â†’  male\n",
      " âœ… Added subject 85: MOTION085_left  â†’  male\n",
      " âœ… Added subject 86: MOTION086_left  â†’  male\n",
      " âœ… Added subject 87: MOTION087_left  â†’  female\n",
      " âœ… Added subject 88: MOTION088_left  â†’  female\n",
      " âœ… Added subject 89: MOTION089_left  â†’  male\n",
      " âœ… Added subject 90: MOTION090_left  â†’  female\n",
      " âœ… Added subject 91: MOTION091_left  â†’  female\n",
      " âœ… Added subject 92: MOTION092_left  â†’  male\n",
      " âœ… Added subject 93: MOTION093_left  â†’  male\n",
      " âœ… Added subject 94: MOTION094_left  â†’  female\n",
      " âœ… Added subject 95: MOTION095_left  â†’  male\n",
      " âœ… Added subject 96: MOTION096_left  â†’  male\n",
      " âœ… Added subject 97: MOTION097_left  â†’  female\n",
      " âœ… Added subject 98: MOTION098_left  â†’  female\n",
      " âœ… Added subject 99: MOTION099_left  â†’  male\n",
      " âœ… Added subject 100: MOTION100_left  â†’  female\n",
      " âœ… Added subject 101: MOTION101_left  â†’  male\n",
      " ðŸ’¾ Project saved to projects/biceps_femoris_long/biceps_femoris_long_novolume_left.swproj\n"
     ]
    }
   ],
   "source": [
    "# Get filenames\n",
    "mesh_extension = '.ply'\n",
    "\n",
    "for modifier in modifiers:\n",
    "    print(f\"\\n=== Processing modifier: {modifier} ===\")\n",
    "    mesh_dir = f\"{muscle_dir}mesh_{modifier}/{side}/\"\n",
    "    mesh_filenames = sorted(glob.glob(mesh_dir + '*' + mesh_extension))\n",
    "    print(f\" Total number of distance transform files: {len(mesh_filenames)}\")\n",
    "\n",
    "    # Get shape names from binary filenames\n",
    "    shape_names = [os.path.splitext(f.split('/')[-1])[0] for f in mesh_filenames]\n",
    "    print(\" Shape names:\", shape_names)\n",
    "\n",
    "    # Parameters\n",
    "    use_single_scale = False  # Set to True for single scale optimization\n",
    "\n",
    "    group_name = [\"sex\"]     # Only grouping by sex\n",
    "    group_values = [\"male\", \"female\"]\n",
    "\n",
    "    subjects = []\n",
    "    number_domains = 1\n",
    "\n",
    "    def extract_id(shape_name):\n",
    "        # Split at the first underscore\n",
    "        base = shape_name.split(\"_\")[0]\n",
    "        return base  # e.g., \"MOTION001\"\n",
    "\n",
    "\n",
    "    for i in range(len(shape_names)):\n",
    "        shape = shape_names[i]\n",
    "        pid = extract_id(shape)\n",
    "\n",
    "        if pid not in id_to_sex:\n",
    "            raise ValueError(f\"PID {pid} from mesh {shape} not found in Excel!\")\n",
    "\n",
    "        sex_group = id_to_sex[pid]   # \"male\" or \"female\"\n",
    "\n",
    "        subject = sw.Subject()\n",
    "        subject.set_number_of_domains(number_domains)\n",
    "        subject.set_groomed_filenames(sw.utils.get_relative_paths([mesh_filenames[i]], project_dir))\n",
    "        subject.set_group_values({group_name[0]: sex_group})\n",
    "\n",
    "        subjects.append(subject)\n",
    "        print(f\" âœ… Added subject {i+1}: {shape}  â†’  {sex_group}\")\n",
    "\n",
    "    # Set up the project\n",
    "    project = sw.Project()\n",
    "    project.set_subjects(subjects)\n",
    "    parameters = sw.Parameters()\n",
    "\n",
    "    # Optimization Parameters\n",
    "    parameter_dictionary = {\n",
    "        \"number_of_particles\": 256,\n",
    "        \"use_normals\": 1,\n",
    "        \"normals_strength\": 10.0,\n",
    "        \"checkpointing_interval\": 200,\n",
    "        \"keep_checkpoints\": 0,\n",
    "        \"iterations_per_split\": 1000,\n",
    "        \"optimization_iterations\": 2000,\n",
    "        \"starting_regularization\": 200,\n",
    "        \"ending_regularization\": 1,\n",
    "        \"initial_relative_weighting\": 0.3,\n",
    "        \"relative_weighting\": 1.0,\n",
    "        \"procrustes_interval\": 0,\n",
    "        \"procrustes_scaling\": 0,\n",
    "        \"save_init_splits\": 1,\n",
    "        \"verbosity\": 0\n",
    "    }\n",
    "\n",
    "    if not use_single_scale:\n",
    "        parameter_dictionary[\"multiscale\"] = 1\n",
    "        parameter_dictionary[\"multiscale_particles\"] = 32\n",
    "\n",
    "    for key in parameter_dictionary:\n",
    "        parameters.set(key, sw.Variant([parameter_dictionary[key]]))\n",
    "    project.set_parameters(\"optimize\", parameters)\n",
    "\n",
    "    # Save\n",
    "    spreadsheet_file = f\"{project_dir}{muscle_name}_{modifier}_{side}.swproj\"\n",
    "    project.save(spreadsheet_file)\n",
    "    print(f\" ðŸ’¾ Project saved to {spreadsheet_file}\")\n",
    "\n",
    "    # Run optimization\n",
    "    optimize_cmd = [\n",
    "        'shapeworks',\n",
    "        'optimize',\n",
    "        '--progress',\n",
    "        '--name',\n",
    "        spreadsheet_file\n",
    "    ]\n",
    "    try:\n",
    "        subprocess.check_call(optimize_cmd)\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\" Optimization for {modifier} failed with error:\")\n",
    "        print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36678de0",
   "metadata": {},
   "source": [
    "# Analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "652d8dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-23 12:59:29.855] [info] ShapeWorks Studio 6.6.1 initializing...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng warning: iCCP: known incorrect sRGB profile\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2026-02-23 12:59:30.759] [info] ShapeWorks Studio Initialized\n",
      "[2026-02-23 12:59:31.429] [info] Loading Project: projects/semimembranosus/semimembranosus_novolume_left.swproj\n",
      "[2026-02-23 12:59:32.472] [info] Project loaded: projects/semimembranosus/semimembranosus_novolume_left.swproj\n",
      "[2026-02-23 12:59:45.478] [info] Wrote: /Users/fadiahanifa/Documents/Akademik/Master/Major Project/Code Deliverables/projects/semimembranosus/semimembranosus_novolume_left_analysis/mean_mesh.vtk\n",
      "[2026-02-23 12:59:47.619] [info] Log Closed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Shut Down Optimization Threads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modifier = [\"rigid\", \"novolume\"][1] ## Change this to select which model's particles to analyze\n",
    "spreadsheet_file = f\"{project_dir}{muscle_name}_{modifier}_{side}.swproj\"\n",
    "\n",
    "analyze_cmd = ('ShapeWorksStudio ' + spreadsheet_file).split()\n",
    "subprocess.check_call(analyze_cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7506255",
   "metadata": {},
   "source": [
    "## Calculate Stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cdfaf36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Found 101 total *_local.particles\n",
      "\n",
      "===== Running PCA for: ALL (101 subjects) =====\n",
      "âœ” Saved standardized scores â€” scores_all_standardized.csv\n",
      "âœ” Saved scaler â€” score_scaler_all.json\n",
      "\n",
      "===== Running PCA for: M (46 subjects) =====\n",
      "âœ” Saved standardized scores â€” scores_m_standardized.csv\n",
      "âœ” Saved scaler â€” score_scaler_m.json\n",
      "\n",
      "===== Running PCA for: F (55 subjects) =====\n",
      "âœ” Saved standardized scores â€” scores_f_standardized.csv\n",
      "âœ” Saved scaler â€” score_scaler_f.json\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# -------- CONFIG --------\n",
    "modifier = [\"rigid\", \"novolume\"][1] ## Change this to select which model's particles to analyze\n",
    "particles_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_particles\")\n",
    "output_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_analysis\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "char_path = \"MOTION_characteristics.xlsx\"\n",
    "\n",
    "\n",
    "# 1. LOAD SEX TABLE (MOTIONXXX â†’ male/female)\n",
    "chars = pd.read_excel(char_path)\n",
    "chars.columns = [c.strip().lower() for c in chars.columns]\n",
    "\n",
    "id_col = [c for c in chars.columns if \"participant\" in c and \"id\" in c][0]\n",
    "sex_col = [c for c in chars.columns if \"sex\" in c][0]\n",
    "\n",
    "sex_map = {}\n",
    "for _, row in chars.iterrows():\n",
    "    pid = str(row[id_col]).strip()\n",
    "    if row[sex_col] == 1:\n",
    "        sex_map[pid] = \"male\"\n",
    "    elif row[sex_col] == 2:\n",
    "        sex_map[pid] = \"female\"\n",
    "\n",
    "# 2. LOAD PARTICLES\n",
    "def load_particles(pdir):\n",
    "    files = sorted([f for f in pdir.glob(\"*local*.particles\")])\n",
    "    shapes = [np.loadtxt(f) for f in files]\n",
    "    return shapes, files\n",
    "\n",
    "shapes_all, files_all = load_particles(particles_dir)\n",
    "print(f\"ðŸ” Found {len(shapes_all)} total *_local.particles\")\n",
    "\n",
    "# Extract subject IDs\n",
    "def extract_subject_id(path):\n",
    "    fname = path.stem\n",
    "    m = re.match(r\"(MOTION\\d+)\", fname)\n",
    "    return m.group(1) if m else fname\n",
    "\n",
    "subject_ids = [extract_subject_id(f) for f in files_all]\n",
    "sex_list = [sex_map.get(pid, None) for pid in subject_ids]\n",
    "\n",
    "# 3ï¸âƒ£ SUBSETS (ALL, M, F)\n",
    "\n",
    "def subset_data(shapes, ids, sexes, group):\n",
    "    if group == \"all\":\n",
    "        idx = list(range(len(shapes)))\n",
    "    else:\n",
    "        idx = [i for i, s in enumerate(sexes) if s == group]\n",
    "\n",
    "    shapes_sub = [shapes[i] for i in idx]\n",
    "    ids_sub = [ids[i] for i in idx]\n",
    "    return shapes_sub, ids_sub\n",
    "\n",
    "subsets = {\n",
    "    \"all\": subset_data(shapes_all, subject_ids, sex_list, \"all\"),\n",
    "    \"m\": subset_data(shapes_all, subject_ids, sex_list, \"male\"),\n",
    "    \"f\": subset_data(shapes_all, subject_ids, sex_list, \"female\"),\n",
    "}\n",
    "\n",
    "# ======================================================\n",
    "# 4ï¸âƒ£ PCA FUNCTION + STANDARDIZATION\n",
    "# ======================================================\n",
    "def run_pca_and_save(shapes, ids, tag=\"all\"):\n",
    "    if len(shapes) == 0:\n",
    "        print(f\"âš ï¸ Skipping {tag}: no samples.\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\n===== Running PCA for: {tag.upper()} ({len(shapes)} subjects) =====\")\n",
    "\n",
    "    # Build matrix\n",
    "    data_matrix = np.stack([s.flatten() for s in shapes])\n",
    "    mean_vector = np.mean(data_matrix, axis=0)\n",
    "    mean_points = mean_vector.reshape(-1, 3)\n",
    "\n",
    "    # Save mean shape\n",
    "    if tag == \"all\":\n",
    "        mean_path = output_dir / \"mean.particles\"\n",
    "    else:\n",
    "        mean_path = output_dir / f\"mean_{tag}.particles\"\n",
    "    np.savetxt(mean_path, mean_points, fmt=\"%.8f\")\n",
    "\n",
    "    # PCA\n",
    "    centered = data_matrix - mean_vector\n",
    "    U, S, VT = np.linalg.svd(centered, full_matrices=False)\n",
    "    eigenvalues = (S**2) / (len(data_matrix) - 1)\n",
    "\n",
    "    # Save modes & eigenvalues\n",
    "    if tag == \"all\":\n",
    "        np.save(output_dir / \"pca_modes.npy\", VT)\n",
    "        np.save(output_dir / \"eigenvalues.npy\", eigenvalues)\n",
    "    else:\n",
    "        np.save(output_dir / f\"pca_modes_{tag}.npy\", VT)\n",
    "        np.save(output_dir / f\"eigenvalues_{tag}.npy\", eigenvalues)\n",
    "\n",
    "    # Raw scores\n",
    "    scores = centered @ VT.T\n",
    "\n",
    "    # -----------------------\n",
    "    # STANDARDIZATION\n",
    "    # -----------------------\n",
    "    score_means = np.mean(scores, axis=0)\n",
    "    score_stds = np.std(scores, axis=0, ddof=1)\n",
    "\n",
    "    scores_z = (scores - score_means) / score_stds\n",
    "\n",
    "    n_modes = scores_z.shape[1]\n",
    "    pc_cols = [f\"PC{i+1}\" for i in range(n_modes)]\n",
    "\n",
    "    # Build dataframe (SubjectID + standardized scores)\n",
    "    df = pd.DataFrame(scores_z, columns=pc_cols)\n",
    "    df.insert(0, \"SubjectID\", ids)\n",
    "\n",
    "    # Output filenames\n",
    "    if tag == \"all\":\n",
    "        scores_path = output_dir / \"scores_all_standardized.csv\"\n",
    "        scaler_path = output_dir / \"score_scaler_all.json\"\n",
    "    else:\n",
    "        scores_path = output_dir / f\"scores_{tag}_standardized.csv\"\n",
    "        scaler_path = output_dir / f\"score_scaler_{tag}.json\"\n",
    "\n",
    "    # Save standardized scores\n",
    "    df.to_csv(scores_path, index=False)\n",
    "    print(f\"âœ” Saved standardized scores â€” {scores_path.name}\")\n",
    "\n",
    "    # Save scaler parameters\n",
    "    scaler_info = {\n",
    "        \"score_means\": score_means.tolist(),\n",
    "        \"score_stds\": score_stds.tolist()\n",
    "    }\n",
    "    with open(scaler_path, \"w\") as f:\n",
    "        json.dump(scaler_info, f, indent=4)\n",
    "\n",
    "    print(f\"âœ” Saved scaler â€” {scaler_path.name}\")\n",
    "\n",
    "# ======================================================\n",
    "# 5ï¸âƒ£ RUN PCA (ALL / M / F)\n",
    "# ======================================================\n",
    "run_pca_and_save(*subsets[\"all\"], tag=\"all\")\n",
    "run_pca_and_save(*subsets[\"m\"], tag=\"m\")\n",
    "run_pca_and_save(*subsets[\"f\"], tag=\"f\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ebe558",
   "metadata": {},
   "source": [
    "# Modes visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa6b5151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------------- CONFIG -------------------------\n",
    "modifier = modifiers[1] ## Change this to select which model's particles to analyze\n",
    "output_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_analysis\")\n",
    "particles_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_particles\")\n",
    "\n",
    "mean_particles_path = output_dir / \"mean.particles\"\n",
    "pca_modes_path = output_dir / \"pca_modes.npy\"\n",
    "eigenvalues_path = output_dir / \"eigenvalues.npy\"\n",
    "scores_path = output_dir / \"scores.csv\"\n",
    "mean_mesh_path = output_dir / \"mean_mesh.vtk\"\n",
    "\n",
    "num_modes_to_visualize = 3\n",
    "std_dev = 2  # for +/-2 std visualization\n",
    "# ----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e40ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to: projects/semimembranosus/semimembranosus_novolume_left_analysis/pcs_heatmaps\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pyvista as pv\n",
    "from scipy.spatial import cKDTree\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "# ----------------------------\n",
    "# CONFIG\n",
    "# ----------------------------\n",
    "k_sd = std_dev                  # visualize mean + k_sd * SD\n",
    "kNN = 5                         # 1 = nearest neighbor, 3â€“10 = smoother mapping\n",
    "window_size = (1200, 1000)\n",
    "cmap = \"PuOr\"               # red=positive(out), blue=negative(in)\n",
    "output_dir = Path(f\"{project_dir}{muscle_name}_{modifier}_{side}_analysis/pcs_heatmaps\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# LOAD\n",
    "# ----------------------------\n",
    "mean_particles = np.loadtxt(mean_particles_path)         # (N, 3)\n",
    "pca_modes = np.load(pca_modes_path)                      # (3N, M) or (M, 3N)\n",
    "eigenvalues = np.load(eigenvalues_path)                  # (M,)\n",
    "mean_mesh = pv.read(mean_mesh_path)\n",
    "\n",
    "# ensure pca_modes is (3N, M)\n",
    "if pca_modes.shape[0] != mean_particles.size:\n",
    "    pca_modes = pca_modes.T\n",
    "assert pca_modes.shape[0] == mean_particles.size, \"Expected pca_modes to be (3N, M) after transpose.\"\n",
    "\n",
    "tree = cKDTree(mean_particles)\n",
    "mesh_pts = mean_mesh.points\n",
    "\n",
    "def muscle_pca_axes(points):\n",
    "    pts = np.asarray(points, dtype=float)\n",
    "    pts = pts - pts.mean(axis=0, keepdims=True)\n",
    "    _, _, vh = np.linalg.svd(pts, full_matrices=False)\n",
    "    return vh  # rows: PC1, PC2, PC3\n",
    "\n",
    "def get_muscle_camera_position(mesh, view=\"cross2\", flip=False, dist_factor=7.5):\n",
    "    axes = muscle_pca_axes(mesh.points)\n",
    "\n",
    "    center = np.asarray(mesh.center, float)\n",
    "    bounds = np.asarray(mesh.bounds, float).reshape(3, 2)\n",
    "    radius = 0.5 * np.linalg.norm(bounds[:, 1] - bounds[:, 0])\n",
    "\n",
    "    if view == \"cross2\":\n",
    "        view_dir = axes[2]\n",
    "        up = axes[0]\n",
    "    elif view == \"cross1\":\n",
    "        view_dir = axes[1]\n",
    "        up = axes[0]\n",
    "    elif view == \"long\":\n",
    "        view_dir = axes[0]\n",
    "        up = axes[2]\n",
    "    else:\n",
    "        raise ValueError(view)\n",
    "\n",
    "    view_dir = np.asarray(view_dir, float)\n",
    "    up = np.asarray(up, float)\n",
    "\n",
    "    view_dir /= (np.linalg.norm(view_dir) + 1e-12)\n",
    "    up /= (np.linalg.norm(up) + 1e-12)\n",
    "\n",
    "    if flip:\n",
    "        view_dir = -view_dir\n",
    "\n",
    "    cam_pos = center + view_dir * radius * dist_factor\n",
    "    return [cam_pos.tolist(), center.tolist(), up.tolist()]\n",
    "\n",
    "\n",
    "def map_vectors_particles_to_mesh(vec_particles, k=1):\n",
    "    \"\"\"vec_particles: (N,3) -> returns (V,3)\"\"\"\n",
    "    if k == 1:\n",
    "        nn_idx = tree.query(mesh_pts, k=1)[1]\n",
    "        return vec_particles[nn_idx]\n",
    "\n",
    "    dists, idxs = tree.query(mesh_pts, k=k)  # (V,k)\n",
    "    w = 1.0 / (dists + 1e-12)\n",
    "    w /= w.sum(axis=1, keepdims=True)\n",
    "    return (vec_particles[idxs] * w[..., None]).sum(axis=1)\n",
    "\n",
    "def signed_normal_displacement(mesh, disp_vec_mesh):\n",
    "    \"\"\"\n",
    "    Returns a copy of mesh with normals computed, and signed displacement (V,)\n",
    "    signed = disp Â· n\n",
    "    \"\"\"\n",
    "    m = mesh.copy()\n",
    "    m.compute_normals(point_normals=True, cell_normals=False, inplace=True,\n",
    "                      auto_orient_normals=True, consistent_normals=True)\n",
    "    n = m.point_normals\n",
    "    signed = np.einsum(\"ij,ij->i\", disp_vec_mesh, n)\n",
    "    return m, signed\n",
    "\n",
    "def save_colorbar_png(\n",
    "    out_path,\n",
    "    cmap=\"PuOr\",\n",
    "    vmin=-1.0,\n",
    "    vmax=1.0,\n",
    "    label=\"Signed normal displacement from mean\",\n",
    "    horizontal=True,\n",
    "    n_ticks=5,\n",
    "    fmt=\"%.2f\",\n",
    "    dpi=300,\n",
    "    transparent=True\n",
    "):\n",
    "    cmap_obj = plt.get_cmap(cmap)\n",
    "    norm = mpl.colors.Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    fig = plt.figure(figsize=(6, 1.2) if horizontal else (1.2, 6))\n",
    "    ax = fig.add_axes([0.05, 0.35, 0.90, 0.35] if horizontal else [0.35, 0.05, 0.35, 0.90])\n",
    "\n",
    "    cb = mpl.colorbar.ColorbarBase(\n",
    "        ax,\n",
    "        cmap=cmap_obj,\n",
    "        norm=norm,\n",
    "        orientation=\"horizontal\" if horizontal else \"vertical\",\n",
    "        ticks=np.linspace(vmin, vmax, n_ticks),\n",
    "        format=mpl.ticker.FormatStrFormatter(fmt),\n",
    "    )\n",
    "    cb.set_label(label)\n",
    "\n",
    "    fig.savefig(out_path, dpi=dpi, transparent=transparent, bbox_inches=\"tight\", pad_inches=0.02)\n",
    "    plt.close(fig)\n",
    "    \n",
    "\n",
    "def visualize_mode_strip(mode_idx):\n",
    "    mode_vec = pca_modes[:, mode_idx].reshape(-1, 3)\n",
    "    sd = float(np.sqrt(eigenvalues[mode_idx]))\n",
    "\n",
    "    # 1 SD displacement field at particles -> mesh\n",
    "    disp_particles_1sd = sd * mode_vec\n",
    "    disp_mesh_1sd = map_vectors_particles_to_mesh(disp_particles_1sd, k=kNN)  # (V,3)\n",
    "\n",
    "    # Compute mean mesh normals ONCE and keep them fixed\n",
    "    mean_with_normals = mean_mesh.copy()\n",
    "    mean_with_normals.compute_normals(\n",
    "        point_normals=True,\n",
    "        cell_normals=False,\n",
    "        inplace=True,\n",
    "        auto_orient_normals=True,\n",
    "        consistent_normals=True\n",
    "    )\n",
    "    normals = mean_with_normals.point_normals  # (V,3)\n",
    "\n",
    "    # Signed normal displacement for 1 SD (scalar per vertex)\n",
    "    signed_1sd = np.einsum(\"ij,ij->i\", disp_mesh_1sd, normals)  # (V,)\n",
    "\n",
    "    # SD steps you want\n",
    "    steps = [-3.0, -1.5, 0.0, 1.5, 3.0]\n",
    "    sd_labels = [\"-3\", \"-1.5\", \"mean\", \"+1.5\", \"+3\"]\n",
    "\n",
    "    # Shared color limits across all 5 panels (based on max step)\n",
    "    max_step = max(abs(s) for s in steps)\n",
    "    clim = (float(np.max(np.abs(signed_1sd)) * max_step) + 1e-12)\n",
    "\n",
    "    p = pv.Plotter(\n",
    "        off_screen=True,\n",
    "        window_size=(3000, 1200),\n",
    "        shape=(1, 5),\n",
    "        border=False,   # removes vertical separators\n",
    "    )\n",
    "\n",
    "    cam_pos = get_muscle_camera_position(mean_mesh, view=\"cross2\", flip=False)\n",
    "\n",
    "    # --- draw the 5 meshes ---\n",
    "    for j, s in enumerate(steps):\n",
    "        p.subplot(0, j)\n",
    "\n",
    "        if s == 0.0:\n",
    "            mesh_s = mean_mesh.copy()\n",
    "        else:\n",
    "            mesh_s = mean_mesh.copy()\n",
    "            mesh_s.points = mean_mesh.points + s * disp_mesh_1sd\n",
    "\n",
    "        # Heatmap scalar: displacement from mean along normals (same reference normals)\n",
    "        mesh_s[\"signed_disp\"] = s * signed_1sd  # (V,)\n",
    "\n",
    "        p.add_mesh(\n",
    "            mesh_s,\n",
    "            scalars=\"signed_disp\",\n",
    "            cmap=cmap,\n",
    "            clim=[-clim, clim],          # SAME scale for all 5\n",
    "            smooth_shading=True,\n",
    "            show_edges=False,\n",
    "            scalar_bar_args=None,         # prevent auto bar\n",
    "            show_scalar_bar=False,        # <-- extra safety across pyvista versions\n",
    "        )\n",
    "\n",
    "        p.camera_position = cam_pos\n",
    "\n",
    "        # ---- SD tick (local to this subplot) ----\n",
    "        if j == 2:\n",
    "            p.add_text(sd_labels[j] + \"\\n\\n\", position=\"lower_edge\", font_size=18)\n",
    "        else:\n",
    "            p.add_text(sd_labels[j] + \"\\n\", position=\"lower_edge\", font_size=18)\n",
    "\n",
    "\n",
    "\n",
    "    # --- GLOBAL TEXT (add once, AFTER the loop) ---\n",
    "    # IMPORTANT: set subplot to middle so older pyvista anchors to the full window more reliably\n",
    "    p.subplot(0, 2)\n",
    "\n",
    "    # Title at top center with margin\n",
    "    var_pct = 100 * eigenvalues[mode_idx] / np.sum(eigenvalues)\n",
    "    p.add_text(\n",
    "        f\"\\nPC {mode_idx+1} ({var_pct:.1f}%)\",\n",
    "        position=\"upper_edge\",\n",
    "        viewport=True,\n",
    "        font_size=24,\n",
    "    )\n",
    "\n",
    "    p.add_text(\n",
    "        \"Standard deviations\",\n",
    "        position=\"lower_edge\",\n",
    "        viewport=True,\n",
    "        font_size=18,\n",
    "    )\n",
    "\n",
    "    # ONE colorbar for the whole figure (attach it while in any subplot)\n",
    "    # clim is currently a positive scalar. Your actual limits are [-clim, clim]\n",
    "    vmin, vmax = -clim, clim\n",
    "\n",
    "    save_colorbar_png(\n",
    "        out_path=output_dir / f\"pc{mode_idx+1}_colorbar.png\",\n",
    "        cmap=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        label= \"Surface normal displacement (mm)\",\n",
    "        horizontal=True,\n",
    "        n_ticks=5,\n",
    "        fmt=\"%.2f\",\n",
    "        dpi=300,\n",
    "        transparent=True\n",
    "    )\n",
    "\n",
    "    p.render()\n",
    "    p.screenshot(str(output_dir / f\"pc{mode_idx+1}_sd_heatmap.png\"))\n",
    "    p.close()\n",
    "\n",
    "# ----------------------------\n",
    "# RUN\n",
    "# ----------------------------\n",
    "for i in range(num_modes_to_visualize):\n",
    "    visualize_mode_strip(i)\n",
    "\n",
    "print(\"Saved to:\", output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b697b5",
   "metadata": {},
   "source": [
    "# Bootstrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c63a541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Loaded 101 valid *_local.particles files from biceps_femoris_long_rigid_left_particles\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40dbdf29e26b49d88a6310c8d04f97c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Bootstrap [biceps_femoris_long_rigid_left_particles]:   0%|          | 0/50 [00:00<?, ?run/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 207\u001b[0m\n\u001b[1;32m    205\u001b[0m boot \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m models:\n\u001b[0;32m--> 207\u001b[0m     boot[m] \u001b[38;5;241m=\u001b[39m \u001b[43mrun_bootstrap_for_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparticles_dir\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mn_boot\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_BOOTSTRAP\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mtrain_frac\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTRAIN_FRAC\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mrng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43mcompute_spec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCOMPUTE_SPECIFICITY\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;66;03m#  PLOTTING + SAVE + DISPLAY\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;66;03m# =========================\u001b[39;00m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_thin_plus_mean\u001b[39m(ax, x, mat, color, label):\n",
      "Cell \u001b[0;32mIn[38], line 178\u001b[0m, in \u001b[0;36mrun_bootstrap_for_model\u001b[0;34m(pdir, n_boot, train_frac, rng, compute_spec)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m compute_spec:\n\u001b[1;32m    176\u001b[0m         per_specF\u001b[38;5;241m.\u001b[39mappend(specificity_forward_curve_msd(train_shapes, mean_vec, modes, eigvals, M_run, rng,\n\u001b[1;32m    177\u001b[0m                                                        n_synth\u001b[38;5;241m=\u001b[39mN_SPEC_SAMPLES_PER_M))\n\u001b[0;32m--> 178\u001b[0m         per_specB\u001b[38;5;241m.\u001b[39mappend(\u001b[43mspecificity_backward_curve_msd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_shapes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m                                                        \u001b[49m\u001b[43mn_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mN_SPEC_POOL_PER_M\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m K_common \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo valid runs produced K_common.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    183\u001b[0m \u001b[38;5;66;03m# truncate all runs to K_common and stack: (R x K)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[38], line 123\u001b[0m, in \u001b[0;36mspecificity_backward_curve_msd\u001b[0;34m(train_shapes, mean_vec, modes, eigvals, M_run, rng, n_pool)\u001b[0m\n\u001b[1;32m    121\u001b[0m vals\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, M_run\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 123\u001b[0m     pool\u001b[38;5;241m=\u001b[39m[sample_random_shape(mean_vec, modes, eigvals, m, rng) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_pool)]\n\u001b[1;32m    124\u001b[0m     dmins\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m train_shapes:\n",
      "Cell \u001b[0;32mIn[38], line 123\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    121\u001b[0m vals\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, M_run\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m--> 123\u001b[0m     pool\u001b[38;5;241m=\u001b[39m[\u001b[43msample_random_shape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_vec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meigvals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_pool)]\n\u001b[1;32m    124\u001b[0m     dmins\u001b[38;5;241m=\u001b[39m[]\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m train_shapes:\n",
      "Cell \u001b[0;32mIn[38], line 107\u001b[0m, in \u001b[0;36msample_random_shape\u001b[0;34m(mean_vec, modes, eigvals, m, rng)\u001b[0m\n\u001b[1;32m    105\u001b[0m m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(m, modes\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mlen\u001b[39m(eigvals))\n\u001b[1;32m    106\u001b[0m a \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mnormal(\u001b[38;5;241m0.0\u001b[39m, np\u001b[38;5;241m.\u001b[39msqrt(np\u001b[38;5;241m.\u001b[39mmaximum(eigvals[:m],\u001b[38;5;241m0.0\u001b[39m)), size\u001b[38;5;241m=\u001b[39mm)\n\u001b[0;32m--> 107\u001b[0m vec \u001b[38;5;241m=\u001b[39m mean_vec \u001b[38;5;241m+\u001b[39m \u001b[43mmodes\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43mm\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m@\u001b[39;49m\u001b[43m \u001b[49m\u001b[43ma\u001b[49m\n\u001b[1;32m    108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m vec\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m3\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "#  DEPENDENCIES\n",
    "# =========================\n",
    "import os, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.utils import resample\n",
    "try:\n",
    "    from tqdm.auto import tqdm\n",
    "    HAS_TQDM = True\n",
    "except Exception:\n",
    "    HAS_TQDM = False\n",
    "\n",
    "def t_range(n, desc=\"\"):\n",
    "    if HAS_TQDM: return tqdm(range(n), total=n, desc=desc, unit=\"run\")\n",
    "    return range(n)\n",
    "\n",
    "# =========================\n",
    "#  CONFIG â€” paths & models\n",
    "# =========================\n",
    "muscle_name = \"biceps_femoris_long\"\n",
    "side = \"left\"\n",
    "models = [\"rigid\", \"novolume\"]\n",
    "extensor = True\n",
    "\n",
    "# particles directories:\n",
    "main_dir = Path(\"projects\") / f\"{muscle_name}\"\n",
    "particles_dir = {m: main_dir / f\"{muscle_name}_{m}_{side}_particles\" for m in models}\n",
    "\n",
    "# Bootstrap params\n",
    "N_BOOTSTRAP = 50\n",
    "TRAIN_FRAC = 0.8\n",
    "SEED = 42\n",
    "rng = np.random.default_rng(SEED)\n",
    "\n",
    "# Specificity params\n",
    "COMPUTE_SPECIFICITY = True\n",
    "N_SPEC_SAMPLES_PER_M = 80   # forward: synth per mode\n",
    "N_SPEC_POOL_PER_M    = 160  # backward: synth pool per mode\n",
    "\n",
    "# =========================\n",
    "#  UTILITIES \n",
    "# =========================\n",
    "def list_all_particles(pdir: Path):\n",
    "    \"\"\"\n",
    "    Loads only *_local.particles files as Nx3 arrays.\n",
    "    Skips malformed or unreadable ones automatically.\n",
    "    \"\"\"\n",
    "    # only use files containing '_local'\n",
    "    files = sorted([f for f in pdir.glob(\"*_local.particles\")])\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No *_local.particles found in {pdir}\")\n",
    "\n",
    "    good, bad = [], []\n",
    "    for f in files:\n",
    "        try:\n",
    "            arr = np.loadtxt(f)\n",
    "            if arr.ndim == 2 and arr.shape[1] == 3:\n",
    "                good.append(arr)\n",
    "            else:\n",
    "                bad.append(f.name)\n",
    "        except Exception:\n",
    "            bad.append(f.name)\n",
    "\n",
    "    if bad:\n",
    "        print(f\"âš ï¸ Skipped {len(bad)} malformed files:\")\n",
    "        print(\"   \", \", \".join(bad[:5]), \"...\" if len(bad) > 5 else \"\")\n",
    "    print(f\"âœ… Loaded {len(good)} valid *_local.particles files from {pdir.name}\")\n",
    "\n",
    "    return good, files\n",
    "\n",
    "\n",
    "def pca_from_shapes(shapes_list):\n",
    "    X = np.stack([s.flatten() for s in shapes_list])     # S x 3N\n",
    "    mean_vec = X.mean(axis=0)\n",
    "    centered = X - mean_vec\n",
    "    U, S, VT = np.linalg.svd(centered, full_matrices=False)\n",
    "    eigvals = (S**2) / (len(X) - 1) if len(X) > 1 else np.zeros_like(S)\n",
    "    modes = VT.T                                        # 3N x M\n",
    "    scores = centered @ VT.T                            # S x M\n",
    "    return mean_vec, modes, eigvals, scores\n",
    "\n",
    "def reconstruct(shape_xyz, mean_vec, modes, n_modes):\n",
    "    n = min(n_modes, modes.shape[1])\n",
    "    coeffs = (shape_xyz.flatten() - mean_vec) @ modes[:, :n]\n",
    "    recon = mean_vec + modes[:, :n] @ coeffs\n",
    "    return recon.reshape(-1,3)\n",
    "\n",
    "def msd(pc1, pc2):\n",
    "    return float(np.mean(np.linalg.norm(pc1-pc2, axis=1)))\n",
    "\n",
    "def hausdorff_distance(pc1, pc2):\n",
    "    t1, t2 = cKDTree(pc1), cKDTree(pc2)\n",
    "    d1, _ = t1.query(pc2); d2, _ = t2.query(pc1)\n",
    "    return float(max(d1.max(), d2.max()))\n",
    "\n",
    "def cumulative_modes_at_threshold(eigvals, thresh=0.95):\n",
    "    ev = np.maximum(np.asarray(eigvals,float),0.0)\n",
    "    tot = ev.sum() if ev.sum()>0 else 1.0\n",
    "    cum = np.cumsum(ev)/tot\n",
    "    return int(np.argmax(cum>=thresh))+1\n",
    "\n",
    "def sample_random_shape(mean_vec, modes, eigvals, m, rng):\n",
    "    m = min(m, modes.shape[1], len(eigvals))\n",
    "    a = rng.normal(0.0, np.sqrt(np.maximum(eigvals[:m],0.0)), size=m)\n",
    "    vec = mean_vec + modes[:, :m] @ a\n",
    "    return vec.reshape(-1,3)\n",
    "\n",
    "def specificity_forward_curve_msd(train_shapes, mean_vec, modes, eigvals, M_run, rng, n_synth=80):\n",
    "    vals=[]\n",
    "    for m in range(1, M_run+1):\n",
    "        dmins=[]\n",
    "        for _ in range(n_synth):\n",
    "            syn = sample_random_shape(mean_vec, modes, eigvals, m, rng)\n",
    "            dmins.append(min(msd(syn, t) for t in train_shapes))\n",
    "        vals.append(float(np.mean(dmins)))\n",
    "    return np.array(vals)\n",
    "\n",
    "def specificity_backward_curve_msd(train_shapes, mean_vec, modes, eigvals, M_run, rng, n_pool=160):\n",
    "    vals=[]\n",
    "    for m in range(1, M_run+1):\n",
    "        pool=[sample_random_shape(mean_vec, modes, eigvals, m, rng) for _ in range(n_pool)]\n",
    "        dmins=[]\n",
    "        for t in train_shapes:\n",
    "            dmins.append(min(msd(t, syn) for syn in pool))\n",
    "        vals.append(float(np.mean(dmins)))\n",
    "    return np.array(vals)\n",
    "\n",
    "# =========================\n",
    "#  BOOTSTRAP per model\n",
    "# =========================\n",
    "def run_bootstrap_for_model(pdir: Path, n_boot=100, train_frac=0.8, rng=None, compute_spec=True):\n",
    "    shapes, _ = list_all_particles(pdir)\n",
    "    N = len(shapes)\n",
    "    if N < 6: raise ValueError(f\"Need >=6 shapes, got {N} in {pdir}\")\n",
    "\n",
    "    per_msd_train, per_msd_test = [], []\n",
    "    per_compactness, per_specF, per_specB = [], [], []\n",
    "    per_m95 = []\n",
    "\n",
    "    K_common = None\n",
    "    for b in t_range(n_boot, f\"Bootstrap [{pdir.name}]\"):\n",
    "        # consistent split sizes, new permutation each run\n",
    "        perm = rng.permutation(N)\n",
    "        ntr = max(1, int(round(train_frac*N)))\n",
    "        train_idx, test_idx = perm[:ntr], perm[ntr:]\n",
    "\n",
    "        train_shapes = [shapes[i] for i in train_idx]\n",
    "        test_shapes  = [shapes[i] for i in test_idx]\n",
    "\n",
    "        mean_vec, modes, eigvals, _ = pca_from_shapes(train_shapes)\n",
    "        if modes.size == 0: continue\n",
    "\n",
    "        # number of usable modes this run\n",
    "        M_run = int(np.sum(eigvals > 0)) if np.any(eigvals>0) else 1\n",
    "        M_run = max(1, min(M_run, modes.shape[1]))\n",
    "        K_common = M_run if K_common is None else min(K_common, M_run)\n",
    "\n",
    "        # curves up to M_run\n",
    "        msd_tr, msd_te = [], []\n",
    "        for m in range(1, M_run+1):\n",
    "            msd_tr.append(np.mean([msd(reconstruct(s, mean_vec, modes, m), s) for s in train_shapes]))\n",
    "            msd_te.append(np.mean([msd(reconstruct(s, mean_vec, modes, m), s) for s in test_shapes]))\n",
    "        per_msd_train.append(np.array(msd_tr))\n",
    "        per_msd_test.append(np.array(msd_te))\n",
    "\n",
    "        # compactness (true cumulative variance of TRAIN eigvals)\n",
    "        ev = np.maximum(np.asarray(eigvals,float),0.0)\n",
    "        tot = ev.sum() if ev.sum()>0 else 1.0\n",
    "        per_compactness.append(np.cumsum(ev[:M_run])/tot)\n",
    "        m95 = cumulative_modes_at_threshold(eigvals, 0.95)\n",
    "        per_m95.append(min(m95, M_run))\n",
    "\n",
    "        if compute_spec:\n",
    "            per_specF.append(specificity_forward_curve_msd(train_shapes, mean_vec, modes, eigvals, M_run, rng,\n",
    "                                                           n_synth=N_SPEC_SAMPLES_PER_M))\n",
    "            per_specB.append(specificity_backward_curve_msd(train_shapes, mean_vec, modes, eigvals, M_run, rng,\n",
    "                                                            n_pool=N_SPEC_POOL_PER_M))\n",
    "\n",
    "    if K_common is None: raise RuntimeError(\"No valid runs produced K_common.\")\n",
    "\n",
    "    # truncate all runs to K_common and stack: (R x K)\n",
    "    def T(stack_list):\n",
    "        return np.stack([arr[:K_common] for arr in stack_list], axis=0)\n",
    "\n",
    "    msd_tr_mat  = T(per_msd_train)\n",
    "    msd_te_mat  = T(per_msd_test)\n",
    "    comp_mat    = T(per_compactness)\n",
    "    specF_mat   = T(per_specF) if per_specF else None\n",
    "    specB_mat   = T(per_specB) if per_specB else None\n",
    "    modes_axis  = np.arange(1, K_common+1)\n",
    "\n",
    "    return {\n",
    "        \"modes\": modes_axis,\n",
    "        \"msd_train\": msd_tr_mat,\n",
    "        \"msd_test\":  msd_te_mat,\n",
    "        \"compactness\": comp_mat,\n",
    "        \"specF\": specF_mat,\n",
    "        \"specB\": specB_mat,\n",
    "        \"m95_list\": np.array(per_m95, int)\n",
    "    }\n",
    "\n",
    "# Run bootstrap for all three models\n",
    "boot = {}\n",
    "for m in models:\n",
    "    boot[m] = run_bootstrap_for_model(particles_dir[m],\n",
    "                                      n_boot=N_BOOTSTRAP,\n",
    "                                      train_frac=TRAIN_FRAC,\n",
    "                                      rng=rng,\n",
    "                                      compute_spec=COMPUTE_SPECIFICITY)\n",
    "\n",
    "# =========================\n",
    "#  PLOTTING + SAVE + DISPLAY\n",
    "# =========================\n",
    "def plot_thin_plus_mean(ax, x, mat, color, label):\n",
    "    \"\"\"Helper: many thin runs + one thick mean.\"\"\"\n",
    "    for row in mat:\n",
    "        ax.plot(x, row, color=color, alpha=0.07, linewidth=1)\n",
    "    ax.plot(x, np.mean(mat, axis=0), color=color, linewidth=3, label=label)\n",
    "\n",
    "\n",
    "# --- ðŸ”¹ Set output folder for all bootstrap figures ---\n",
    "save_dir = main_dir\n",
    "\n",
    "# ===================================================\n",
    "# 1ï¸âƒ£ COMPACTNESS (with 95% mark)\n",
    "# ===================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "for i, m in enumerate(models):\n",
    "    x = boot[m][\"modes\"]\n",
    "    comp = boot[m][\"compactness\"]\n",
    "    plot_thin_plus_mean(axes[i], x, comp, \"green\", \"Compactness (mean)\")\n",
    "    m95_med = int(np.median(boot[m][\"m95_list\"]))\n",
    "    axes[i].axvline(m95_med, color=\"gray\", linestyle=\"--\", label=f\"95% @ {m95_med}\")\n",
    "    axes[i].set_title(m.upper())\n",
    "    axes[i].set_xlabel(\"Number of Modes\")\n",
    "    axes[i].set_ylim(0, 1.0)\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"Cumulative Variance Explained\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.suptitle(f\"{muscle_name.upper()} â€” Compactness (Bootstrap {N_BOOTSTRAP}Ã—, 80/20)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show\n",
    "comp_path = save_dir / f\"{muscle_name}_compactness_bootstrap.png\"\n",
    "plt.savefig(comp_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\" Saved compactness plot: {comp_path}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 2ï¸âƒ£ MSD (train vs test)\n",
    "# ===================================================\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "for i, m in enumerate(models):\n",
    "    x = boot[m][\"modes\"]\n",
    "    plot_thin_plus_mean(axes[i], x, boot[m][\"msd_test\"], \"red\", \"Test MSD (mean)\")\n",
    "    plot_thin_plus_mean(axes[i], x, boot[m][\"msd_train\"], \"blue\", \"Train MSD (mean)\")\n",
    "    axes[i].set_title(m.upper())\n",
    "    axes[i].set_xlabel(\"Number of Modes\")\n",
    "    if i == 0:\n",
    "        axes[i].set_ylabel(\"MSD (mm)\")\n",
    "    axes[i].legend()\n",
    "\n",
    "plt.suptitle(f\"{muscle_name.upper()} â€” MSD vs Modes (Bootstrap {N_BOOTSTRAP}Ã—, 80/20)\", y=1.02)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Save and show\n",
    "msd_path = save_dir / f\"{muscle_name}_msd_bootstrap.png\"\n",
    "plt.savefig(msd_path, dpi=300, bbox_inches=\"tight\")\n",
    "print(f\" Saved MSD plot: {msd_path}\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 3ï¸âƒ£ SPECIFICITY (forward/backward)\n",
    "# ===================================================\n",
    "if COMPUTE_SPECIFICITY:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(12,4), sharey=True)\n",
    "    for i, m in enumerate(models):\n",
    "        x = boot[m][\"modes\"]\n",
    "        if boot[m][\"specF\"] is not None:\n",
    "            plot_thin_plus_mean(axes[i], x, boot[m][\"specF\"], \"orange\", \"Specificity Forward (mean)\")\n",
    "        if boot[m][\"specB\"] is not None:\n",
    "            plot_thin_plus_mean(axes[i], x, boot[m][\"specB\"], \"purple\", \"Specificity Backward (mean)\")\n",
    "        axes[i].set_title(m.upper())\n",
    "        axes[i].set_xlabel(\"Number of Modes\")\n",
    "        if i == 0:\n",
    "            axes[i].set_ylabel(\"Mean min-MSD (mm)\")\n",
    "        axes[i].legend()\n",
    "\n",
    "    plt.suptitle(f\"{muscle_name.upper()} â€” Specificity vs Modes (Bootstrap {N_BOOTSTRAP}Ã—, 80/20)\", y=1.02)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save and show\n",
    "    spec_path = save_dir / f\"{muscle_name}_specificity_bootstrap.png\"\n",
    "    plt.savefig(spec_path, dpi=300, bbox_inches=\"tight\")\n",
    "    print(f\"ðŸ’¾ Saved Specificity plot: {spec_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# ===================================================\n",
    "#  PRINT SUMMARY @ PC=3 (mean Â± SD across bootstraps)\n",
    "# ===================================================\n",
    "PC = 3\n",
    "\n",
    "def mean_sd(x):\n",
    "    x = np.asarray(x, float)\n",
    "    return float(np.mean(x)), float(np.std(x, ddof=1)) if x.size > 1 else (float(np.mean(x)), 0.0)\n",
    "\n",
    "rows = []\n",
    "for m in models:\n",
    "    K = boot[m][\"modes\"].size\n",
    "    if K < PC:\n",
    "        print(f\"âš ï¸ {m}: only {K} common modes available, cannot report PC{PC}.\")\n",
    "        continue\n",
    "\n",
    "    idx = PC - 1\n",
    "\n",
    "    comp_pc = boot[m][\"compactness\"][:, idx]\n",
    "    gen_pc  = boot[m][\"msd_test\"][:, idx]\n",
    "\n",
    "    comp_mean, comp_sd = mean_sd(comp_pc)\n",
    "    gen_mean, gen_sd   = mean_sd(gen_pc)\n",
    "\n",
    "    if boot[m][\"specF\"] is not None:\n",
    "        specF_mean, specF_sd = mean_sd(boot[m][\"specF\"][:, idx])\n",
    "    else:\n",
    "        specF_mean, specF_sd = (np.nan, np.nan)\n",
    "\n",
    "    if boot[m][\"specB\"] is not None:\n",
    "        specB_mean, specB_sd = mean_sd(boot[m][\"specB\"][:, idx])\n",
    "    else:\n",
    "        specB_mean, specB_sd = (np.nan, np.nan)\n",
    "\n",
    "    rows.append({\n",
    "        \"model\": m,\n",
    "        \"compactness@PC3_mean\": comp_mean,\n",
    "        \"compactness@PC3_SD\": comp_sd,\n",
    "        \"generalizability_testMSD@PC3_mean_mm\": gen_mean,\n",
    "        \"generalizability_testMSD@PC3_SD_mm\": gen_sd,\n",
    "        \"specificity_forward@PC3_mean_mm\": specF_mean,\n",
    "        \"specificity_forward@PC3_SD_mm\": specF_sd,\n",
    "        \"specificity_backward@PC3_mean_mm\": specB_mean,\n",
    "        \"specificity_backward@PC3_SD_mm\": specB_sd,\n",
    "        \"n_boot_runs\": boot[m][\"msd_test\"].shape[0],\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(rows)\n",
    "\n",
    "print(\"\\n===== Bootstrap summary at PC3 =====\")\n",
    "print(summary_df.to_string(index=False))\n",
    "\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ee9b7a2",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5c05266",
   "metadata": {},
   "source": [
    "## Single Muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf7378d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Modifier: rigid ---\n",
      "\n",
      "--- Modifier: novolume ---\n",
      "\n",
      "âœ” Saved: regression/semimembranosus_mixedlm_PC3.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG â€” SINGLE MUSCLE\n",
    "# ============================================================\n",
    "muscle_name = \"semimembranosus\"   # CHANGE as needed\n",
    "IS_FLEXOR   = False               # False extensor, True flexor\n",
    "side = \"left\"\n",
    "\n",
    "modifiers = [\"rigid\", \"novolume\"]\n",
    "N_PCS = 3\n",
    "\n",
    "chars_path = Path(\"MOTION_characteristics.xlsx\")\n",
    "project_dir = Path(\"projects\")\n",
    "\n",
    "# ============================================================\n",
    "# FORCE COLUMN (ISOM ONLY)\n",
    "# ============================================================\n",
    "outcome_col = \"avpt_isom_k_f\" if IS_FLEXOR else \"avpt_isom_k_e\"\n",
    "\n",
    "# ============================================================\n",
    "# LOAD CHARACTERISTICS (only need outcome here)\n",
    "# ============================================================\n",
    "chars_raw = pd.read_excel(chars_path)\n",
    "chars_raw.columns = [c.lower().strip() for c in chars_raw.columns]\n",
    "if \"participant id\" not in chars_raw.columns:\n",
    "    raise ValueError(\"Expected column 'participant id' in MOTION_characteristics.xlsx\")\n",
    "\n",
    "chars = chars_raw[[\"participant id\", outcome_col]].copy()\n",
    "chars = chars.rename(columns={\"participant id\": \"participant_id\"})\n",
    "chars[\"participant_id\"] = chars[\"participant_id\"].astype(str).str.upper()\n",
    "\n",
    "chars[outcome_col] = pd.to_numeric(chars[outcome_col], errors=\"coerce\")\n",
    "chars = chars.dropna(subset=[outcome_col])\n",
    "chars = chars[chars[outcome_col] >= 0].copy()\n",
    "chars = chars.drop_duplicates(subset=[\"participant_id\"])\n",
    "\n",
    "# ============================================================\n",
    "# LOAD ORIGINAL VOLUMES (LEFT SIDE ONLY)\n",
    "# ============================================================\n",
    "volpath = Path(f\"data/{muscle_name}/{muscle_name}_original_volumes.csv\")\n",
    "vol_df = pd.read_csv(volpath)\n",
    "\n",
    "if \"shape_name\" not in vol_df.columns or \"original_volume_mm3\" not in vol_df.columns:\n",
    "    raise ValueError(f\"{volpath} must contain shape_name and original_volume_mm3\")\n",
    "\n",
    "vol_df = vol_df[vol_df[\"shape_name\"].str.contains(\"_left\", case=False, na=False)].copy()\n",
    "\n",
    "def extract_left_id(name):\n",
    "    m = re.search(r\"(?i)(motion\\d+)_left\", str(name))\n",
    "    return m.group(1).upper() if m else None\n",
    "\n",
    "vol_df[\"participant_id\"] = vol_df[\"shape_name\"].apply(extract_left_id)\n",
    "vol_df = vol_df.dropna(subset=[\"participant_id\"]).copy()\n",
    "\n",
    "vol_df[\"original_volume_mm3\"] = pd.to_numeric(vol_df[\"original_volume_mm3\"], errors=\"coerce\")\n",
    "vol_df = vol_df.dropna(subset=[\"original_volume_mm3\"]).copy()\n",
    "\n",
    "# if duplicates exist, average per subject\n",
    "vol_df = vol_df.groupby(\"participant_id\", as_index=False)[\"original_volume_mm3\"].mean()\n",
    "\n",
    "# z-score volume\n",
    "vol_df[\"volume_z\"] = (\n",
    "    vol_df[\"original_volume_mm3\"] - vol_df[\"original_volume_mm3\"].mean()\n",
    ") / vol_df[\"original_volume_mm3\"].std(ddof=0)\n",
    "\n",
    "vol_df = vol_df[[\"participant_id\", \"volume_z\"]]\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PC SCORES\n",
    "# ============================================================\n",
    "def load_pc_single(muscle, modifier):\n",
    "    path = (\n",
    "        project_dir /\n",
    "        muscle /\n",
    "        f\"{muscle}_{modifier}_{side}_analysis\" /\n",
    "        \"scores_all_standardized.csv\"\n",
    "    )\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "\n",
    "    # normalize ID column to participant_id\n",
    "    for cand in [\"participant_id\", \"participant id\", \"id\", \"subjectid\", \"subject_id\"]:\n",
    "        if cand in df.columns:\n",
    "            df = df.rename(columns={cand: \"participant_id\"})\n",
    "            break\n",
    "    if \"participant_id\" not in df.columns:\n",
    "        raise ValueError(f\"No subject ID column found in {path}\")\n",
    "\n",
    "    df[\"participant_id\"] = df[\"participant_id\"].astype(str).str.upper()\n",
    "\n",
    "    pc_cols = sorted([c for c in df.columns if c.startswith(\"pc\")],\n",
    "                     key=lambda x: int(x.replace(\"pc\", \"\")))[:N_PCS]\n",
    "\n",
    "    out = df[[\"participant_id\"] + pc_cols].copy()\n",
    "    for c in pc_cols:\n",
    "        out[c] = pd.to_numeric(out[c], errors=\"coerce\")\n",
    "    out = out.dropna(subset=pc_cols)\n",
    "\n",
    "    # ensure names are pc1..pcN\n",
    "    rename_map = {pc_cols[i]: f\"pc{i+1}\" for i in range(len(pc_cols))}\n",
    "    out = out.rename(columns=rename_map)\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# TABLE BUILDERS\n",
    "# ============================================================\n",
    "def mixedlm_tables_with_fitinfo(res):\n",
    "    params = res.params\n",
    "    bse = res.bse\n",
    "    zval = params / bse\n",
    "    pvals = res.pvalues\n",
    "    ci = res.conf_int()\n",
    "    ci.columns = [\"ci_low\", \"ci_high\"]\n",
    "\n",
    "    coef_df = pd.concat([params, bse, zval, pvals, ci], axis=1)\n",
    "    coef_df.columns = [\"coef\", \"std_err\", \"z\", \"p_value\", \"ci_low\", \"ci_high\"]\n",
    "    coef_df = coef_df.reset_index().rename(columns={\"index\": \"term\"})\n",
    "\n",
    "    fit_info = pd.DataFrame([\n",
    "        {\"term\": \"AIC\",       \"coef\": getattr(res, \"aic\", np.nan)},\n",
    "        {\"term\": \"BIC\",       \"coef\": getattr(res, \"bic\", np.nan)},\n",
    "        {\"term\": \"logLik\",    \"coef\": getattr(res, \"llf\", np.nan)},\n",
    "        {\"term\": \"n_obs\",     \"coef\": getattr(res, \"nobs\", np.nan)},\n",
    "        {\"term\": \"k_params\",  \"coef\": len(getattr(res, \"params\", []))},\n",
    "        {\"term\": \"converged\", \"coef\": int(bool(getattr(res, \"converged\", False)))},\n",
    "        {\"term\": \"reml\",      \"coef\": 0},  # ML fit\n",
    "    ])\n",
    "    for c in [\"std_err\", \"z\", \"p_value\", \"ci_low\", \"ci_high\"]:\n",
    "        fit_info[c] = np.nan\n",
    "\n",
    "    return pd.concat([coef_df, fit_info], ignore_index=True)\n",
    "\n",
    "# ============================================================\n",
    "# OUTPUT FILE\n",
    "# ============================================================\n",
    "output_dir = Path(\"regression\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "file_path = output_dir / f\"{muscle_name}_mixedlm_PC{N_PCS}.xlsx\"\n",
    "\n",
    "# ============================================================\n",
    "# RUN MODELS: PC-only + VOLUME-only + PC+volume\n",
    "# IMPORTANT: reml=False so AIC/BIC exist\n",
    "# ============================================================\n",
    "with pd.ExcelWriter(file_path, engine=\"openpyxl\", mode=\"w\") as writer:\n",
    "\n",
    "    for modifier in modifiers:\n",
    "        print(f\"\\n--- Modifier: {modifier} ---\")\n",
    "\n",
    "        pc_df = load_pc_single(muscle_name, modifier)\n",
    "\n",
    "        df = (\n",
    "            pc_df\n",
    "            .merge(chars, on=\"participant_id\", how=\"inner\")\n",
    "            .merge(vol_df, on=\"participant_id\", how=\"inner\")\n",
    "        )\n",
    "\n",
    "        df[outcome_col] = pd.to_numeric(df[outcome_col], errors=\"coerce\")\n",
    "        df = df.dropna(subset=[outcome_col])\n",
    "        df = df[df[outcome_col] >= 0].copy()\n",
    "\n",
    "        pcs = [f\"pc{i}\" for i in range(1, N_PCS + 1)]\n",
    "\n",
    "        # -------------------------\n",
    "        # MODEL 1: PC ONLY\n",
    "        # -------------------------\n",
    "        formula1 = f\"{outcome_col} ~ \" + \" + \".join(pcs)\n",
    "        sheet1 = f\"{modifier}_pc_only\"\n",
    "        data1 = f\"{sheet1}_DATA\"\n",
    "\n",
    "        try:\n",
    "            res1 = smf.mixedlm(formula1, df, groups=df[\"participant_id\"], re_formula=\"1\").fit(\n",
    "                method=\"lbfgs\", maxiter=500, reml=False\n",
    "            )\n",
    "            mixedlm_tables_with_fitinfo(res1).to_excel(writer, index=False, sheet_name=sheet1)\n",
    "            # df[[\"participant_id\", outcome_col] + pcs].to_excel(writer, index=False, sheet_name=data1)\n",
    "        except Exception as e:\n",
    "            pd.DataFrame({\"error\": [str(e)], \"formula\": [formula1]}).to_excel(writer, index=False, sheet_name=sheet1)\n",
    "\n",
    "        # -------------------------\n",
    "        # MODEL 2: PC + VOLUME\n",
    "        # -------------------------\n",
    "        formula2 = f\"{outcome_col} ~ \" + \" + \".join(pcs + [\"volume_z\"])\n",
    "        sheet2 = f\"{modifier}_pc+volume\"\n",
    "        data2 = f\"{sheet2}_DATA\"\n",
    "\n",
    "        try:\n",
    "            res2 = smf.mixedlm(formula2, df, groups=df[\"participant_id\"], re_formula=\"1\").fit(\n",
    "                method=\"lbfgs\", maxiter=500, reml=False\n",
    "            )\n",
    "            mixedlm_tables_with_fitinfo(res2).to_excel(writer, index=False, sheet_name=sheet2)\n",
    "            # df[[\"participant_id\", outcome_col] + pcs + [\"volume_z\"]].to_excel(writer, index=False, sheet_name=data2)\n",
    "        except Exception as e:\n",
    "            pd.DataFrame({\"error\": [str(e)], \"formula\": [formula2]}).to_excel(writer, index=False, sheet_name=sheet2)\n",
    "    \n",
    "    # -------------------------\n",
    "    # MODEL 3: VOLUME ONLY\n",
    "    # -------------------------\n",
    "    formula3 = f\"{outcome_col} ~ volume_z\"\n",
    "    sheet3 = f\"{modifier}_volume\"\n",
    "    data3 = f\"{sheet2}_DATA\"\n",
    "\n",
    "    try:\n",
    "        res2 = smf.mixedlm(formula2, df, groups=df[\"participant_id\"], re_formula=\"1\").fit(\n",
    "            method=\"lbfgs\", maxiter=500, reml=False\n",
    "        )\n",
    "        mixedlm_tables_with_fitinfo(res3).to_excel(writer, index=False, sheet_name=sheet3)\n",
    "        # df[[\"participant_id\", outcome_col, \"volume_z\"]].to_excel(writer, index=False, sheet_name=data3)\n",
    "    except Exception as e:\n",
    "        pd.DataFrame({\"error\": [str(e)], \"formula\": [formula3]}).to_excel(writer, index=False, sheet_name=sheet3)\n",
    "\n",
    "print(\"\\nâœ” Saved:\", file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f01099d",
   "metadata": {},
   "source": [
    "## Multi Muscle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "94c278bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muscles in group: ['biceps_femoris_long', 'biceps_femoris_short', 'semitendinosus', 'semimembranosus']\n",
      "[CLEAN] chars_outcome: before=126 after_dropna_inf=115\n",
      "[INFO] vol_wide shape: (101, 5)\n",
      "[INFO] non-missing per volume column:\n",
      " biceps_femoris_long_vol_z     101\n",
      "biceps_femoris_short_vol_z    101\n",
      "semitendinosus_vol_z          101\n",
      "semimembranosus_vol_z         101\n",
      "dtype: int64\n",
      "\n",
      "=== Modifier: rigid ===\n",
      "[CLEAN] biceps_femoris_long_rigid_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] biceps_femoris_short_rigid_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] semitendinosus_rigid_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] semimembranosus_rigid_pcs: before=101 after_dropna_inf=101\n",
      "[INFO] rigid pre-drop shape: (97, 18)\n",
      "[CLEAN] rigid_pc_only_df: before=97 after_dropna_inf=97\n",
      "[FORMULA pc_only] avpt_isom_k_f ~ biceps_femoris_long_pc1 + biceps_femoris_long_pc2 + biceps_femoris_long_pc3 + biceps_femoris_short_pc1 + biceps_femoris_short_pc2 + biceps_femoris_short_pc3 + semitendinosus_pc1 + semitendinosus_pc2 + semitendinosus_pc3 + semimembranosus_pc1 + semimembranosus_pc2 + semimembranosus_pc3\n",
      "[CLEAN] rigid_pc_musclevol_df: before=97 after_dropna_inf=97\n",
      "[FORMULA pc_musclevol] avpt_isom_k_f ~ biceps_femoris_long_pc1 + biceps_femoris_long_pc2 + biceps_femoris_long_pc3 + biceps_femoris_short_pc1 + biceps_femoris_short_pc2 + biceps_femoris_short_pc3 + semitendinosus_pc1 + semitendinosus_pc2 + semitendinosus_pc3 + semimembranosus_pc1 + semimembranosus_pc2 + semimembranosus_pc3 + biceps_femoris_long_vol_z + biceps_femoris_short_vol_z + semitendinosus_vol_z + semimembranosus_vol_z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Modifier: novolume ===\n",
      "[CLEAN] biceps_femoris_long_novolume_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] biceps_femoris_short_novolume_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] semitendinosus_novolume_pcs: before=101 after_dropna_inf=101\n",
      "[CLEAN] semimembranosus_novolume_pcs: before=101 after_dropna_inf=101\n",
      "[INFO] novolume pre-drop shape: (97, 18)\n",
      "[CLEAN] novolume_pc_only_df: before=97 after_dropna_inf=97\n",
      "[FORMULA pc_only] avpt_isom_k_f ~ biceps_femoris_long_pc1 + biceps_femoris_long_pc2 + biceps_femoris_long_pc3 + biceps_femoris_short_pc1 + biceps_femoris_short_pc2 + biceps_femoris_short_pc3 + semitendinosus_pc1 + semitendinosus_pc2 + semitendinosus_pc3 + semimembranosus_pc1 + semimembranosus_pc2 + semimembranosus_pc3\n",
      "[CLEAN] novolume_pc_musclevol_df: before=97 after_dropna_inf=97\n",
      "[FORMULA pc_musclevol] avpt_isom_k_f ~ biceps_femoris_long_pc1 + biceps_femoris_long_pc2 + biceps_femoris_long_pc3 + biceps_femoris_short_pc1 + biceps_femoris_short_pc2 + biceps_femoris_short_pc3 + semitendinosus_pc1 + semitendinosus_pc2 + semitendinosus_pc3 + semimembranosus_pc1 + semimembranosus_pc2 + semimembranosus_pc3 + biceps_femoris_long_vol_z + biceps_femoris_short_vol_z + semitendinosus_vol_z + semimembranosus_vol_z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n",
      "/Users/fadiahanifa/miniconda3/envs/shapeworks/lib/python3.9/site-packages/statsmodels/regression/mixed_linear_model.py:2261: ConvergenceWarning: The Hessian matrix at the estimated parameter values is not positive definite.\n",
      "  warnings.warn(msg, ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "âœ” Saved: regression/flexor_group_left_mixedlm_PC3.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import statsmodels.formula.api as smf\n",
    "import re\n",
    "\n",
    "# ============================================================\n",
    "# CONFIG\n",
    "# ============================================================\n",
    "project_dir = Path(\"projects\")\n",
    "group_is_flexor = True\n",
    "side = \"left\"\n",
    "modifiers = [\"rigid\", \"novolume\"]\n",
    "N_PCS = 3\n",
    "\n",
    "chars_path = Path(\"MOTION_characteristics.xlsx\")\n",
    "group_dir = \"flexor_group_left\" if group_is_flexor else \"extensor_group_left\"\n",
    "\n",
    "if group_is_flexor:\n",
    "    muscle_list = [\"biceps_femoris_long\", \"biceps_femoris_short\", \"semitendinosus\", \"semimembranosus\"]\n",
    "    outcome_col = \"avpt_isom_k_f\"\n",
    "else:\n",
    "    muscle_list = [\"vastus_lateralis\", \"vastus_medialis\", \"vastus_intermedius\", \"rectus_femoris\"]\n",
    "    outcome_col = \"avpt_isom_k_e\"\n",
    "output_dir = Path(\"regression\")\n",
    "\n",
    "print(\"Muscles in group:\", muscle_list)\n",
    "\n",
    "# ============================================================\n",
    "# HELPERS\n",
    "# ============================================================\n",
    "def safe_zscore(x: pd.Series) -> pd.Series:\n",
    "    x = pd.to_numeric(x, errors=\"coerce\")\n",
    "    mu = x.mean()\n",
    "    sd = x.std(ddof=0)\n",
    "    if not np.isfinite(sd) or sd == 0:\n",
    "        return pd.Series(np.zeros(len(x)), index=x.index)\n",
    "    return (x - mu) / sd\n",
    "\n",
    "def coerce_and_filter(df: pd.DataFrame, cols, name=\"df\"):\n",
    "    df = df.copy()\n",
    "    for c in cols:\n",
    "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    before = len(df)\n",
    "    df = df.dropna(subset=cols)\n",
    "    after = len(df)\n",
    "    print(f\"[CLEAN] {name}: before={before} after_dropna_inf={after}\")\n",
    "    if after == 0:\n",
    "        raise ValueError(f\"{name} became empty after cleaning on columns: {cols}\")\n",
    "    return df\n",
    "\n",
    "def coef_table(res):\n",
    "    ci = res.conf_int()\n",
    "    ci.columns = [\"ci_low\", \"ci_high\"]\n",
    "    out = pd.concat(\n",
    "        [res.params.rename(\"coef\"),\n",
    "         res.bse.rename(\"std_err\"),\n",
    "         res.pvalues.rename(\"p\"),\n",
    "         ci],\n",
    "        axis=1\n",
    "    ).reset_index().rename(columns={\"index\": \"term\"})\n",
    "    return out\n",
    "\n",
    "def model_stats_row(res, model_name, modifier, formula):\n",
    "    # MixedLM AIC/BIC are only defined for ML fits (reml=False)\n",
    "    return {\n",
    "        \"model\": model_name,\n",
    "        \"modifier\": modifier,\n",
    "        \"formula\": formula,\n",
    "        \"n_obs\": int(res.nobs),\n",
    "        \"k_params\": int(len(res.params)),\n",
    "        \"logLik\": float(res.llf),\n",
    "        \"AIC\": float(res.aic),\n",
    "        \"BIC\": float(res.bic),\n",
    "        \"converged\": bool(getattr(res, \"converged\", False)),\n",
    "        \"reml\": False,\n",
    "    }\n",
    "\n",
    "# ============================================================\n",
    "# SUBJECT-LEVEL OUTCOME (TORQUE)\n",
    "# ============================================================\n",
    "chars = pd.read_excel(chars_path)\n",
    "chars.columns = [c.lower().strip() for c in chars.columns]\n",
    "chars = chars.rename(columns={\"participant id\": \"participant_id\"})\n",
    "chars[\"participant_id\"] = chars[\"participant_id\"].astype(str).str.upper()\n",
    "\n",
    "if outcome_col not in chars.columns:\n",
    "    raise ValueError(f\"{outcome_col} not found in MOTION_characteristics.xlsx\")\n",
    "\n",
    "chars = chars[[\"participant_id\", outcome_col]].copy()\n",
    "chars = coerce_and_filter(chars, [outcome_col], name=\"chars_outcome\")\n",
    "chars = chars[chars[outcome_col] >= 0].copy()\n",
    "chars = chars.drop_duplicates(subset=[\"participant_id\"])\n",
    "\n",
    "# ============================================================\n",
    "# MUSCLE VOLUME PER MUSCLE (LEFT ONLY) -> wide columns: <muscle>_vol_z\n",
    "# NOTE: do NOT drop rows here (outer merge); complete-case later.\n",
    "# ============================================================\n",
    "vol_wide = None\n",
    "for muscle in muscle_list:\n",
    "    vdf = pd.read_csv(f\"data/{muscle}/{muscle}_original_volumes.csv\")\n",
    "    if \"shape_name\" not in vdf.columns or \"original_volume_mm3\" not in vdf.columns:\n",
    "        raise ValueError(f\"{muscle}_original_volumes.csv must contain shape_name and original_volume_mm3\")\n",
    "\n",
    "    vdf = vdf[vdf[\"shape_name\"].str.contains(f\"_{side}\", case=False, na=False)].copy()\n",
    "    vdf[\"participant_id\"] = vdf[\"shape_name\"].str.extract(r\"(MOTION\\d+)\")[0].astype(str).str.upper()\n",
    "    vdf = vdf.dropna(subset=[\"participant_id\"]).copy()\n",
    "\n",
    "    vdf[\"original_volume_mm3\"] = pd.to_numeric(vdf[\"original_volume_mm3\"], errors=\"coerce\")\n",
    "    vdf = vdf.dropna(subset=[\"original_volume_mm3\"]).copy()\n",
    "\n",
    "    vdf = vdf.groupby(\"participant_id\", as_index=False)[\"original_volume_mm3\"].mean()\n",
    "    vdf[f\"{muscle}_vol_z\"] = safe_zscore(vdf[\"original_volume_mm3\"])\n",
    "    vdf = vdf[[\"participant_id\", f\"{muscle}_vol_z\"]]\n",
    "\n",
    "    vol_wide = vdf if vol_wide is None else vol_wide.merge(vdf, on=\"participant_id\", how=\"outer\")\n",
    "\n",
    "vol_terms = [f\"{m}_vol_z\" for m in muscle_list]\n",
    "for c in vol_terms:\n",
    "    vol_wide[c] = pd.to_numeric(vol_wide[c], errors=\"coerce\")\n",
    "\n",
    "print(\"[INFO] vol_wide shape:\", vol_wide.shape)\n",
    "print(\"[INFO] non-missing per volume column:\\n\", vol_wide[vol_terms].notna().sum())\n",
    "\n",
    "# ============================================================\n",
    "# LOAD PCs â€” WIDE PER MUSCLE\n",
    "# ============================================================\n",
    "def load_muscle_pcs(muscle, modifier):\n",
    "    path = (\n",
    "        project_dir / muscle /\n",
    "        f\"{muscle}_{modifier}_{side}_analysis\" /\n",
    "        \"scores_all_standardized.csv\"\n",
    "    )\n",
    "    df = pd.read_csv(path)\n",
    "    df.columns = [c.lower().strip() for c in df.columns]\n",
    "\n",
    "    if \"subjectid\" in df.columns:\n",
    "        df = df.rename(columns={\"subjectid\": \"participant_id\"})\n",
    "    elif \"participant id\" in df.columns:\n",
    "        df = df.rename(columns={\"participant id\": \"participant_id\"})\n",
    "    elif \"participant_id\" not in df.columns:\n",
    "        raise ValueError(f\"No subject ID column in {path}\")\n",
    "\n",
    "    df[\"participant_id\"] = df[\"participant_id\"].astype(str).str.upper()\n",
    "\n",
    "    pcs = [f\"pc{i}\" for i in range(1, N_PCS + 1)]\n",
    "    missing = [p for p in pcs if p not in df.columns]\n",
    "    if missing:\n",
    "        raise ValueError(f\"Missing PCs {missing} in {path}\")\n",
    "\n",
    "    out = df[[\"participant_id\"] + pcs].copy()\n",
    "    out = coerce_and_filter(out, pcs, name=f\"{muscle}_{modifier}_pcs\")\n",
    "\n",
    "    out = out.rename(columns={\n",
    "        \"pc1\": f\"{muscle}_pc1\",\n",
    "        \"pc2\": f\"{muscle}_pc2\",\n",
    "        \"pc3\": f\"{muscle}_pc3\",\n",
    "    })\n",
    "    return out\n",
    "\n",
    "# ============================================================\n",
    "# BUILD SUBJECT-LEVEL TABLE\n",
    "# ============================================================\n",
    "def build_subject_table(modifier):\n",
    "    dfs = [load_muscle_pcs(m, modifier) for m in muscle_list]\n",
    "\n",
    "    subj_df = dfs[0]\n",
    "    for d in dfs[1:]:\n",
    "        subj_df = subj_df.merge(d, on=\"participant_id\", how=\"inner\")\n",
    "\n",
    "    subj_df = (\n",
    "        subj_df\n",
    "        .merge(chars, on=\"participant_id\", how=\"inner\")\n",
    "        .merge(vol_wide, on=\"participant_id\", how=\"left\")\n",
    "    )\n",
    "\n",
    "    pc_terms = []\n",
    "    for m in muscle_list:\n",
    "        pc_terms += [f\"{m}_pc1\", f\"{m}_pc2\", f\"{m}_pc3\"]\n",
    "\n",
    "    vol_terms_local = [f\"{m}_vol_z\" for m in muscle_list]\n",
    "\n",
    "    # complete-case for the *volume model* will happen later;\n",
    "    # for now we return full table and lists\n",
    "    print(f\"[INFO] {modifier} pre-drop shape:\", subj_df.shape)\n",
    "    return subj_df, pc_terms, vol_terms_local\n",
    "\n",
    "# ============================================================\n",
    "# FIT MIXED MODEL (ML so AIC/BIC exist)\n",
    "# ============================================================\n",
    "def fit_model(df, formula):\n",
    "    model = smf.mixedlm(formula, df, groups=df[\"participant_id\"], re_formula=\"1\")\n",
    "    return model.fit(method=\"lbfgs\", maxiter=800, reml=False)  # <-- ML!\n",
    "\n",
    "# ============================================================\n",
    "# RUN MODELS\n",
    "# ============================================================\n",
    "all_stats = []\n",
    "output_path = output_dir / f\"{group_dir}_mixedlm_PC{N_PCS}.xlsx\"\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "    # always keep at least one visible sheet\n",
    "    for mod in modifiers:\n",
    "        print(f\"\\n=== Modifier: {mod} ===\")\n",
    "        subj_df, pc_terms, vol_terms_local = build_subject_table(mod)\n",
    "\n",
    "        # -------------------------\n",
    "        # MODEL 1: PC ONLY\n",
    "        # -------------------------\n",
    "        need_cols_1 = [\"participant_id\", outcome_col] + pc_terms\n",
    "        df1 = subj_df[need_cols_1].copy()\n",
    "        df1 = coerce_and_filter(df1, [outcome_col] + pc_terms, name=f\"{mod}_pc_only_df\")\n",
    "        df1 = df1[df1[outcome_col] >= 0].copy()\n",
    "\n",
    "        f1 = f\"{outcome_col} ~ \" + \" + \".join(pc_terms)\n",
    "        print(\"[FORMULA pc_only]\", f1)\n",
    "\n",
    "        try:\n",
    "            res1 = fit_model(df1, f1)\n",
    "            c1 = coef_table(res1)\n",
    "            # append fit info to coef sheet\n",
    "            fit_info1 = pd.DataFrame([\n",
    "                {\"term\": \"AIC\", \"coef\": res1.aic, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"BIC\", \"coef\": res1.bic, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"logLik\", \"coef\": res1.llf, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"n_obs\", \"coef\": res1.nobs, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"converged\", \"coef\": int(res1.converged), \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "            ])\n",
    "            pd.concat([c1, fit_info1], ignore_index=True).to_excel(writer, sheet_name=f\"{mod}_pc_only\", index=False)\n",
    "\n",
    "            # data + fitted + resid\n",
    "            d1 = df1.copy()\n",
    "            d1[\"fitted\"] = np.asarray(res1.fittedvalues)\n",
    "            d1[\"resid\"] = np.asarray(res1.resid)\n",
    "            d1[\"std_resid\"] = d1[\"resid\"] / np.sqrt(res1.scale) if np.isfinite(res1.scale) and res1.scale > 0 else np.nan\n",
    "            # d1.to_excel(writer, sheet_name=f\"{mod}_pc_only_DATA\", index=False)\n",
    "\n",
    "            all_stats.append(model_stats_row(res1, \"pc_only\", mod, f1))\n",
    "\n",
    "        except Exception as e:\n",
    "            pd.DataFrame([{\"modifier\": mod, \"model\": \"pc_only\", \"error\": str(e), \"formula\": f1}]).to_excel(\n",
    "                writer, sheet_name=f\"{mod}_pc_only_ERR\"[:31], index=False\n",
    "            )\n",
    "\n",
    "        # -------------------------\n",
    "        # MODEL 2: PC + PER-MUSCLE VOLUME\n",
    "        # -------------------------\n",
    "        need_cols_2 = [\"participant_id\", outcome_col] + pc_terms + vol_terms_local\n",
    "        df2 = subj_df[need_cols_2].copy()\n",
    "        df2 = coerce_and_filter(df2, [outcome_col] + pc_terms + vol_terms_local, name=f\"{mod}_pc_musclevol_df\")\n",
    "        df2 = df2[df2[outcome_col] >= 0].copy()\n",
    "\n",
    "        f2 = f\"{outcome_col} ~ \" + \" + \".join(pc_terms + vol_terms_local)\n",
    "        print(\"[FORMULA pc_musclevol]\", f2)\n",
    "\n",
    "        try:\n",
    "            res2 = fit_model(df2, f2)\n",
    "            c2 = coef_table(res2)\n",
    "            fit_info2 = pd.DataFrame([\n",
    "                {\"term\": \"AIC\", \"coef\": res2.aic, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"BIC\", \"coef\": res2.bic, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"logLik\", \"coef\": res2.llf, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"n_obs\", \"coef\": res2.nobs, \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "                {\"term\": \"converged\", \"coef\": int(res2.converged), \"std_err\": np.nan, \"p\": np.nan, \"ci_low\": np.nan, \"ci_high\": np.nan},\n",
    "            ])\n",
    "            pd.concat([c2, fit_info2], ignore_index=True).to_excel(writer, sheet_name=f\"{mod}_pc_musclevol\", index=False)\n",
    "\n",
    "            d2 = df2.copy()\n",
    "            d2[\"fitted\"] = np.asarray(res2.fittedvalues)\n",
    "            d2[\"resid\"] = np.asarray(res2.resid)\n",
    "            d2[\"std_resid\"] = d2[\"resid\"] / np.sqrt(res2.scale) if np.isfinite(res2.scale) and res2.scale > 0 else np.nan\n",
    "            #d2.to_excel(writer, sheet_name=f\"{mod}_pc_musclevol_DATA\", index=False)\n",
    "\n",
    "            all_stats.append(model_stats_row(res2, \"pc+volume\", mod, f2))\n",
    "\n",
    "        except Exception as e:\n",
    "            pd.DataFrame([{\"modifier\": mod, \"model\": \"pc+volume\", \"error\": str(e), \"formula\": f2}]).to_excel(\n",
    "                writer, sheet_name=f\"{mod}_pc_musclevol_ERR\"[:31], index=False\n",
    "            )\n",
    "print(\"\\nâœ” Saved:\", output_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "shapeworks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
